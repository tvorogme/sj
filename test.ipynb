{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:31:01.376260Z",
     "start_time": "2018-02-08T15:31:01.373816Z"
    },
    "cell_style": "split",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/profilum/profilum/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:31:01.386906Z",
     "start_time": "2018-02-08T15:31:01.377755Z"
    },
    "cell_style": "split",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:31:16.471891Z",
     "start_time": "2018-02-08T15:31:01.446115Z"
    },
    "cell_style": "center",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from fn.monad import optionable\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.orm import *\n",
    "from db import *\n",
    "from joblib import delayed, Parallel\n",
    "import gensim\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from lxml.html import document_fromstring\n",
    "from lxml.etree import tounicode\n",
    "from utils import *\n",
    "from currency_converter import CurrencyConverter, RateNotFoundError\n",
    "from lib.hh_uskills import get_uskills\n",
    "import pickle\n",
    "nltk.data.path.append(\"/home/profilum/.nltk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:31:16.663623Z",
     "start_time": "2018-02-08T15:31:16.502643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CurrencyConverterApi = CurrencyConverter()\n",
    "\n",
    "# Those currencies are not supported by api\n",
    "not_supported = {\n",
    "    'RUR': 1,\n",
    "    'KZT': 0.180672506,\n",
    "    'BYR': 30.33,\n",
    "    'UAH': 2.15411133,\n",
    "    'AZN': 33.59\n",
    "}\n",
    "\n",
    "\n",
    "def convert_price(cost_currency_date: list) -> int:\n",
    "    '''Convert vacancy sallary'''\n",
    "\n",
    "    # Get API of CurrencyConverter\n",
    "    global CurrencyConverterApi, not_supported\n",
    "\n",
    "    # Set cost, currency, date\n",
    "    cost = cost_currency_date[0]\n",
    "    currency = cost_currency_date[1]\n",
    "    open_time = cost_currency_date[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:34:31.780340Z",
     "start_time": "2018-02-08T15:31:16.664769Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_raws = session.query(Raw).filter(Raw.http_errcode == None).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:34:34.533142Z",
     "start_time": "2018-02-08T15:34:34.485974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(html: str, raw_id: int) -> dict:\n",
    "    \"\"\"Parse raw html into a Vacancy.\"\"\"\n",
    "\n",
    "    # FIXME: handle `html == ''`\n",
    "    html = html.replace('<li>', '\\n').replace('</li>', '\\n').replace(\n",
    "        '<p>', '\\n').replace('</p>', '\\n')\n",
    "\n",
    "    # Parse html\n",
    "    root = document_fromstring(html)\n",
    "\n",
    "    # Get time of creating\n",
    "    time = root.xpath(\"//time\")\n",
    "\n",
    "    if len(time) > 0:\n",
    "        time = time[0].get('datetime')\n",
    "\n",
    "        if time:\n",
    "            # Parse time\n",
    "            time = time.split(\"T\")[0]\n",
    "            time = datetime.strptime(time, \"%Y-%m-%d\")\n",
    "    else:\n",
    "        time = None\n",
    "\n",
    "    # Try to get the price from meta\n",
    "    try:\n",
    "        # Get currency {'AZN', 'BYR', 'EUR', 'KZT', 'RUR', 'UAH', 'USD'}\n",
    "        currency = root.xpath(\"//meta[contains(@itemprop,'salaryCurrency')]\")[\n",
    "            0].get('content')\n",
    "\n",
    "        # Get price\n",
    "        cost = int(\n",
    "            root.xpath(\"//meta[contains(@itemprop,'baseSalary')]\")[0].get(\n",
    "                'content'))\n",
    "\n",
    "        # Convert it\n",
    "        rub_for_job = convert_price([cost, currency, time])\n",
    "\n",
    "    except IndexError:\n",
    "        # з/п не указана\n",
    "        rub_for_job = 0\n",
    "\n",
    "    # Find text\n",
    "    text = root.xpath(\"//div[contains(@class,'b-vacancy-desc-wrapper')]\")[0]\n",
    "    # Got it!\n",
    "    text = text.text_content()\n",
    "\n",
    "    return {\n",
    "        'open_time': time,\n",
    "        'text': text,\n",
    "        'salary': rub_for_job,\n",
    "        'raw_id': raw_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:39:34.246586Z",
     "start_time": "2018-02-08T15:34:35.209468Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 15160 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 53880 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=12)]: Done 108088 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=12)]: Done 177784 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=12)]: Done 262968 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=12)]: Done 363640 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=12)]: Done 479800 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done 611448 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=12)]: Done 758584 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=12)]: Done 921208 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=12)]: Done 1099320 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=12)]: Done 1292920 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=12)]: Done 1502008 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=12)]: Done 1628453 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=12)]: Done 1748485 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=12)]: Done 1876261 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=12)]: Done 2011781 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=12)]: Done 2120454 out of 2120454 | elapsed:  4.8min finished\n"
     ]
    }
   ],
   "source": [
    "new_parsed = Parallel(\n",
    "    n_jobs=12, verbose=3)(delayed(parse)(x.html, x.id) for x in all_raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:40:04.998765Z",
     "start_time": "2018-02-08T15:40:04.660156Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_texts = {i['raw_id']: i['text'] for i in new_parsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:42:32.460102Z",
     "start_time": "2018-02-08T15:40:59.182675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vacancies = session.query(Vacancy).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:43:34.739575Z",
     "start_time": "2018-02-08T15:43:31.171640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 841447/841447 [00:03<00:00, 236943.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(all_vacancies))):\n",
    "    all_vacancies[i].text = new_texts[all_vacancies[i].raw_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Достаём скиллы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:44:32.596125Z",
     "start_time": "2018-02-08T15:44:32.576196Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@optionable\n",
    "def cut_by_semmarkers(description: str):\n",
    "    description = description.lower()\n",
    "    \n",
    "    a = \"\"\n",
    "    for i in ['кандидатам:', 'требования:', 'обязанности:']:\n",
    "        if i in description:\n",
    "            a += description.split(i)[1].split(':')[0]\n",
    "\n",
    "#         re.match(\n",
    "#         r'(требования|обязанности):.*?:',\n",
    "#         description,\n",
    "#         flags=(re.IGNORECASE + re.DOTALL))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:45:30.399201Z",
     "start_time": "2018-02-08T15:45:30.358864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_skill(a):\n",
    "    main_skill = a\n",
    "    repl = lambda x: x.replace(',', '|').replace(\n",
    "                    ' или ', '|').replace(' и ', '|').replace('/', '|').split('|')\n",
    "    \n",
    "    first_match = re.match(r'([а-яА-ЯA-Za-z\\-\\s]*([,и\\/]|или)\\s)', a)\n",
    "\n",
    "    if first_match:\n",
    "        first_match = first_match.group()\n",
    "        a = repl(a.replace(first_match, ''))\n",
    "\n",
    "        for i in a:\n",
    "            if len(i.split()) > 4:\n",
    "                return repl(main_skill)\n",
    "        \n",
    "        variants = first_match.replace(',', ' ').replace(\n",
    "            ' или ', ' ').replace(' и ', ' ').replace('/', ' ')\n",
    "        variants = list(filter(len, variants.split(' ')))\n",
    "        if len(variants) > 1:\n",
    "            main_phrase = variants[:-1]\n",
    "            a.append(variants[-1])\n",
    "\n",
    "            skills = []\n",
    "\n",
    "            for i in a:\n",
    "                skills.append(\" \".join(main_phrase + [i]))\n",
    "            return skills\n",
    "        else:\n",
    "            return a + variants\n",
    "    else:\n",
    "        return [a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:46:28.294648Z",
     "start_time": "2018-02-08T15:46:28.260531Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_skills(text: str) -> List[str]:\n",
    "    def _split_into_skills(x):\n",
    "        # Here we try fix split problem\n",
    "        # If it is capital letter - maybe new skill...\n",
    "        x = re.sub(r'([А-ЯA-Z])', r'\\n\\1', text)\n",
    "        # Не работает при сокращениях\n",
    "        return re.split(r'[\\n\\.]', x)\n",
    "\n",
    "    pre_skills = list(nonempty(_split_into_skills(text)))\n",
    "    done_skills = []\n",
    "\n",
    "    for skill in pre_skills:\n",
    "        skill = skill.replace('/', ' / ').replace(\"\\xa0\", \" \")\n",
    "        if len(re.findall(\"\\([а-яА-ЯA-Za-z\\-\\s]*\\)\", skill)) > 0:\n",
    "            skill1 = re.findall(r'\\([а-яА-ЯA-Za-z\\-\\s]*\\)', skill)[0]\n",
    "            skill2 = re.findall(r'[а-яА-ЯA-Za-z\\-\\s]*\\(', skill)[0][:-1]\n",
    "            done_skills.extend([skill1, skill2])\n",
    "        elif len(re.findall(\"([а-яА-ЯA-Za-z\\-\\s]*([,и\\/]|или)\\s[а-яА-ЯA-Za-z\\-])\", skill)) > 0:\n",
    "            new_skills = split_skill(skill)\n",
    "            if new_skills:\n",
    "                done_skills.extend(new_skills)\n",
    "\n",
    "        else:\n",
    "            done_skills.append(skill)\n",
    "    return done_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:47:26.255913Z",
     "start_time": "2018-02-08T15:47:26.207320Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stopwords = nltk.corpus.stopwords.words(\n",
    "    'russian') + nltk.corpus.stopwords.words('english')\n",
    "stopwords += [\n",
    "    'отличный', 'метр', 'наш', 'клиент', 'банка', 'е', 'проект', 'литр', 'ы', \n",
    "    'желательный', 'др', 'ч', 'самый', 'чело', 'мочь', 'хороший', 'год', 'чел', 'чело', 'обязательный'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:48:24.064922Z",
     "start_time": "2018-02-08T15:48:24.049486Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_skills(text: str) -> Iterable[str]:\n",
    "    return cut_by_semmarkers(text) \\\n",
    "        .map(split_into_skills) \\\n",
    "        .get_or([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:49:21.932223Z",
     "start_time": "2018-02-08T15:49:21.861315Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = {}\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def normalize_skill(skill: str):\n",
    "\n",
    "    def get_words(text):\n",
    "        return re.findall(r'\\w+', text)\n",
    "\n",
    "    def normal_form(word):\n",
    "        if word not in helper:\n",
    "            helper[word] = morph.parse(word)[0]\n",
    "        return helper[word].normal_form\n",
    "\n",
    "    filter_stopwords = filter(lambda word: word not in stopwords)\n",
    "\n",
    "    def _get_POS(word):\n",
    "        if word not in helper:\n",
    "            helper[word] = morph.parse(word)[0]\n",
    "        return helper[word].tag.POS\n",
    "\n",
    "    filter_POS = filter(lambda word: _get_POS(word) in ['NOUN', \"ADJF\", 'INFN'])\n",
    "    \n",
    "    parsed = tuple(\n",
    "        pipe(\n",
    "            skill,\n",
    "            lambda x: x.lower(),\n",
    "            remove_numbers,\n",
    "            get_words,\n",
    "        ))\n",
    "    \n",
    "    clear_skill = []\n",
    "    dirty_skill = []\n",
    "    \n",
    "    last_stopword = None\n",
    "    \n",
    "    for i in parsed:\n",
    "        word = normal_form(i)\n",
    "    \n",
    "        if word in nltk.corpus.stopwords.words('russian'):\n",
    "            last_stopword = word\n",
    "        elif _get_POS(word) in ['NOUN', # NOUN\n",
    "                                \"ADJF\", # ADJ\n",
    "                                'INFN', # VERB\n",
    "                                'VERB', # VERB\n",
    "                                'ADJS'  # ADJ\n",
    "                               ] and len(word) > 3 and word not in stopwords:\n",
    "            if last_stopword and len(dirty_skill) > 0:\n",
    "                dirty_skill.append(last_stopword)\n",
    "                last_stopword = None\n",
    "            clear_skill.append(word)\n",
    "            if _get_POS(word) in ['NOUN', 'ADJF']:\n",
    "                dirty_skill.append(i)\n",
    "        elif word in ['рф', 'пк']:\n",
    "            dirty_skill.append(word)\n",
    "        \n",
    "    if len(clear_skill) > 1 and len(clear_skill) < 8:\n",
    "        return clear_skill, dirty_skill\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:50:33.667949Z",
     "start_time": "2018-02-08T15:50:19.726625Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"/home/profilum/profilum/ruwikiruscorpora_0_300_20.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:51:31.557539Z",
     "start_time": "2018-02-08T15:51:31.539025Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp_vector = np.array([0] * 300, dtype=np.float32)\n",
    "def _word2vec(word):\n",
    "    for i in [\"_NOUN\", \"_ADJ\", \"_VERB\"]:\n",
    "        tmp = \"{}{}\".format(word, i)\n",
    "        if tmp in model:\n",
    "            return model[tmp]\n",
    "        else:\n",
    "            return tmp_vector\n",
    "skill_to_vec = lambda x: sum(list(map(_word2vec, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:52:29.324797Z",
     "start_time": "2018-02-08T15:52:29.309154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_skills(description: str) -> Iterable[str]:\n",
    "    skills = tuple(find_skills(description))\n",
    "    return tuple(pipe(\n",
    "        skills,\n",
    "        map(normalize_skill),\n",
    "        filter(len)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T15:53:26.804245Z",
     "start_time": "2018-02-08T15:53:26.788646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = random.choice(list(all_vacancies))\n",
    "# i = 0\n",
    "# while len(get_skills(a.text)) == 0:\n",
    "#     print(\"\\r Skipped %s\" % i, end=\"\")\n",
    "#     a = random.choice(list(all_vacancies))\n",
    "#     i+=1\n",
    "# skills = get_skills(a.text)\n",
    "# [{\"vector\": skill_to_vec(i[0]), \"skill\": \" \".join(i[0]), \"real_skill\": \" \".join(i[1])} for i in skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-08T15:31:11.369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    skills = get_skills(x.text)\n",
    "    answer = [{\"vector\": skill_to_vec(i[0]), \"skill\": \" \".join(i[0]), \"real_skill\": \" \".join(i[1])} for i in skills]\n",
    "    return (x.id, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T16:14:13.761794Z",
     "start_time": "2017-12-20T15:53:43.268488Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = Parallel(n_jobs=-1, verbose=3, max_nbytes='1G')(delayed(f)(x) for x in all_vacancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T11:38:05.561907Z",
     "start_time": "2018-01-11T11:38:02.235Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vac_to_skills = {c[0]: c[1] for c in tqdm(values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-08T15:31:16.749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(vac_to_skills, open(\"vac_to_skills.pck\", \"wb\"))\n",
    "vac_to_skills = pickle.load(open(\"vac_to_skills.pck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-08T15:31:21.668Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skill_to_id = {}\n",
    "skill_id_to_skill = {}\n",
    "skill_to_skill = {}\n",
    "skill_id_to_vec = {}\n",
    "r = Counter()\n",
    "a = 0\n",
    "j = 0\n",
    "for key in tqdm(vac_to_skills):\n",
    "    for _dict in vac_to_skills[key]:\n",
    "        if _dict[\"skill\"] not in skill_to_id:\n",
    "            skill_to_id[_dict[\"skill\"]] = a\n",
    "            skill_id_to_skill[a] = _dict[\"skill\"]\n",
    "            skill_to_skill[_dict[\"skill\"]] = _dict[\"real_skill\"]\n",
    "            skill_id_to_vec[a] = _dict[\"vector\"]\n",
    "            a += 1\n",
    "        r[_dict[\"skill\"]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:45.314827Z",
     "start_time": "2018-01-11T12:31:43.092009Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whitelist = set([i[0] for i in r.most_common(500000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:14:19.457833Z",
     "start_time": "2018-01-12T10:14:14.060284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 841447/841447 [00:05<00:00, 156544.83it/s]\n"
     ]
    }
   ],
   "source": [
    "skill_to_id = {}\n",
    "skill_id_to_skill = {}\n",
    "skill_to_skill = {}\n",
    "skill_id_to_vec = {}\n",
    "a = 0\n",
    "j = 0\n",
    "for key in tqdm(vac_to_skills):\n",
    "    for _dict in vac_to_skills[key]:\n",
    "        if _dict[\"skill\"] in whitelist:\n",
    "            if _dict[\"skill\"] not in skill_to_id:\n",
    "                skill_to_id[_dict[\"skill\"]] = a\n",
    "                skill_id_to_skill[a] = _dict[\"skill\"]\n",
    "                skill_to_skill[_dict[\"skill\"]] = _dict[\"real_skill\"]\n",
    "                skill_id_to_vec[a] = _dict[\"vector\"]\n",
    "                a += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:09.711265Z",
     "start_time": "2018-01-10T14:12:05.466364Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:18.115440Z",
     "start_time": "2018-01-10T14:12:09.712599Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_cos_sim_theano():\n",
    "    v1 = theano.tensor.vector(dtype='float32')\n",
    "    v2 = theano.tensor.vector(dtype='float32')\n",
    "    \n",
    "    numerator = theano.tensor.sum(v1*v2)\n",
    "    denominator = theano.tensor.sqrt(theano.tensor.sum(v1**2)*theano.tensor.sum(v2**2))\n",
    "   \n",
    "    return theano.function([v1, v2], numerator/denominator)\n",
    "\n",
    "cos_sim_theano_fn = compile_cos_sim_theano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:18.130776Z",
     "start_time": "2018-01-10T14:12:18.116695Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:19.215050Z",
     "start_time": "2018-01-10T14:12:18.131940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_skills_id = defaultdict(lambda: [])\n",
    "\n",
    "for _id in skill_id_to_skill:\n",
    "    for word in set(skill_id_to_skill[_id].split()):\n",
    "        words_to_skills_id[word].append(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:19.238670Z",
     "start_time": "2018-01-10T14:12:19.216283Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "a = 0\n",
    "for word in words_to_skills_id.keys():\n",
    "    word_to_id[word] = a\n",
    "    id_to_word[a] = word\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:32.481102Z",
     "start_time": "2018-01-10T14:12:19.239951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = dok_matrix((len(words_to_skills_id.keys()), len(skill_id_to_skill.keys())), dtype=np.float16)\n",
    "\n",
    "for word, skills in tqdm(words_to_skills_id.items()):\n",
    "    word_id = word_to_id[word]\n",
    "    for skill in skills:\n",
    "        mat[word_id, skill] = 1\n",
    "    \n",
    "mat = mat.transpose().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:12:33.168508Z",
     "start_time": "2018-01-10T14:12:32.482263Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Вспомогательная штука\n",
    "_skill_id_to_skill = {x: set(skill_id_to_skill[x].split()) for x in skill_id_to_skill}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:26:43.921143Z",
     "start_time": "2018-01-10T14:12:33.169692Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Пересечения скиллов\n",
    "_len1 = mat * mat.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:26:44.617483Z",
     "start_time": "2018-01-10T14:26:44.005644Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__data = _len1.data\n",
    "__indptr = _len1.indptr\n",
    "__indices = _len1.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:26:44.652281Z",
     "start_time": "2018-01-10T14:26:44.630173Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Посчитаем длинну\n",
    "get_lenghts_of_sum_words = lambda current, new: len(_skill_id_to_skill[new]) + len(_skill_id_to_skill[current])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:53.674476Z",
     "start_time": "2018-01-11T12:31:51.407877Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_skill_id_to_skill = {x: set(skill_id_to_skill[x].split()) for x in skill_id_to_skill}\n",
    "skill_id_to_vec = {x: np.asarray(skill_id_to_vec[x], dtype=np.float32) for x in skill_id_to_vec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:53.690012Z",
     "start_time": "2018-01-11T12:31:53.675665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skill_id_to_vec_lambda = lambda x: np.asarray(skill_id_to_vec[x], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:28:48.809116Z",
     "start_time": "2018-01-10T14:28:48.653988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(index_current):\n",
    "    index_new = __indices[__indptr[index_current]:__indptr[index_current+1]]\n",
    "    lenght = np.asarray([get_lenghts_of_sum_words(index_current, item) for item in index_new])\n",
    "    iskl = lenght - 2 * __data[__indptr[index_current]:__indptr[index_current+1]]\n",
    "    \n",
    "    # Достанем вектора\n",
    "    sim = map(lambda x: skill_id_to_vec_lambda(x), index_new)\n",
    "    current_skill_vector = skill_id_to_vec_lambda(index_current)\n",
    "\n",
    "    # Посчитаем косинус там где нужно\n",
    "    sim = np.asarray(list(map(lambda x: float(cos_sim_theano_fn(current_skill_vector, x)), sim)))\n",
    "    sim = sim / iskl\n",
    "    _len1 = __data[__indptr[index_current]:__indptr[index_current+1]]\n",
    "    counter = Counter({x:y/0.4 for x,y in zip(index_new, _len1/lenght * sim/iskl)}).most_common()\n",
    "    answer = []\n",
    "    \n",
    "    for i in counter:\n",
    "        if i[1] > 0.5:\n",
    "            answer.append(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return (index_current, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-25T06:25:00.182Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Parallel(n_jobs=-1, verbose=3, max_nbytes='10G')(delayed(f)(x) for x in range(1, _len1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T18:58:41.029732Z",
     "start_time": "2017-12-25T18:58:40.802051Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_simmilar = {x[0]: x[1] for x in tqdm(data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T19:00:36.109968Z",
     "start_time": "2017-12-25T19:00:27.788538Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(id_to_simmilar, open(\"similars.pck\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:54.854173Z",
     "start_time": "2018-01-11T12:31:53.690985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_simmilar = pickle.load(open(\"similars.pck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:55.425053Z",
     "start_time": "2018-01-11T12:31:54.855320Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499999/499999 [00:00<00:00, 906642.63it/s]\n"
     ]
    }
   ],
   "source": [
    "blacklist = set()\n",
    "\n",
    "for i in tqdm(id_to_simmilar):\n",
    "    if i not in blacklist:\n",
    "        a = [k[0] for k in id_to_simmilar[i]]\n",
    "        if i in a:\n",
    "            a.remove(i)\n",
    "        blacklist.update(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:55.906396Z",
     "start_time": "2018-01-11T12:31:55.426140Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in blacklist:\n",
    "    if i != 0:\n",
    "        del id_to_simmilar[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сервисы\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:02:39.242659Z",
     "start_time": "2018-01-12T10:02:04.542831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 841447/841447 [00:33<00:00, 24830.31it/s]\n"
     ]
    }
   ],
   "source": [
    "goal = {}\n",
    "years = set()\n",
    "\n",
    "for vac in tqdm(all_vacancies):\n",
    "    for skill in vac_to_skills[vac.id]:\n",
    "        if skill['skill'] in goal:\n",
    "            goal[skill['skill']] += [[\n",
    "                vac.salary, vac.open_time.year, vac.open_time.month\n",
    "            ]]\n",
    "        else:\n",
    "            goal[skill['skill']] = [[\n",
    "                vac.salary, vac.open_time.year, vac.open_time.month\n",
    "            ]]\n",
    "    years.add(vac.open_time.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:09:45.197381Z",
     "start_time": "2018-01-12T10:08:20.496064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341322/341322 [01:24<00:00, 4030.84it/s]\n"
     ]
    }
   ],
   "source": [
    "new_cool = {}\n",
    "for uskill in tqdm(id_to_simmilar):\n",
    "    top_similar = [skill_id_to_skill[i[0]] for i in id_to_simmilar[uskill]] + [skill_id_to_skill[uskill]]\n",
    "    new_cool[skill_to_skill[skill_id_to_skill[uskill]]] = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for skill in top_similar:\n",
    "        vacs = goal[skill]\n",
    "        \n",
    "        for vac in vacs:\n",
    "            new_cool[skill_to_skill[skill_id_to_skill[uskill]]][vac[1]][vac[2]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T11:58:18.262018Z",
     "start_time": "2018-01-11T11:58:18.140338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = list(filter(lambda x: type(x) is str, list(new_cool.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T11:58:21.340403Z",
     "start_time": "2018-01-11T11:58:21.290920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(text, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-29T11:57:31.599745Z",
     "start_time": "2017-12-29T11:57:30.744707Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-29T11:59:21.192472Z",
     "start_time": "2017-12-29T11:57:32.198883Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year in tqdm(list(reversed(list(years)))):\n",
    "    data_proto = data.copy()\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        data_proto['size_%s' % month] = [new_cool[p][year][month]\n",
    "                                         for p in data_proto['text']]\n",
    "        #data_proto['size_%s' % month] = data_proto['size_%s' % month]/data_proto['size_%s' % month].max()\n",
    "        data_proto = data_proto.fillna(0)\n",
    "\n",
    "    def f(g):\n",
    "        return sum([g[i] for i in g])\n",
    "\n",
    "    data_proto['size_year'] = [f(new_cool[p][year])\n",
    "                               for p in data_proto['text']]\n",
    "    data_proto = data_proto.sort_values(['size_year'], ascending=False)[\n",
    "        :20000].to_csv('output/data_{}.csv'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-29T12:00:38.530105Z",
     "start_time": "2017-12-29T12:00:35.385243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm output.zip\n",
    "!zip -r output.zip output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:56.579110Z",
     "start_time": "2018-01-11T12:31:55.907568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_skill_to_vec = {skill_to_skill[x]: skill_id_to_vec[skill_to_id[x]] for x in skill_to_skill}\n",
    "clear_skill_to_id = {skill_to_skill[x]: skill_to_id[x] for x in skill_to_skill}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:56.599674Z",
     "start_time": "2018-01-11T12:31:56.580281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, inf), (77280, 0.88587385416030895), (676, 0.87538653612136841)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_simmilar[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:21:34.758105Z",
     "start_time": "2018-01-12T09:21:32.470526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341322/341322 [00:02<00:00, 159748.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from lib import hh_uskills\n",
    "vectors = []\n",
    "\n",
    "for main_skill_id in tqdm(id_to_simmilar.keys()):\n",
    "    skills = [pair[0] for pair in id_to_simmilar[main_skill_id]] + [main_skill_id]\n",
    "    vector = sum(list(map(lambda _id: skill_id_to_vec[_id], skills))) \n",
    "    vectors.append(vector)\n",
    "\n",
    "items = dict(zip(id_to_simmilar.keys(), vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:58.893162Z",
     "start_time": "2018-01-11T12:31:58.878648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-11T12:31:58.972968Z",
     "start_time": "2018-01-11T12:31:58.894249Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = MulticoreTSNE(n_jobs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:22:16.597149Z",
     "start_time": "2018-01-12T09:22:16.530862Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "\n",
    "for key in list(items.keys()):\n",
    "    all_vectors.append(items[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:22:17.809599Z",
     "start_time": "2018-01-12T09:22:17.499951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = np.asarray(all_vectors).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-12T09:22:18.605Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = tsne.fit_transform(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:19:37.861854Z",
     "start_time": "2018-01-12T10:19:37.562806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for key, i in zip(items.keys(), range(len(all_vectors))):\n",
    "    vectors[skill_to_skill[skill_id_to_skill[key]]] = all_vectors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:19:38.985853Z",
     "start_time": "2018-01-12T10:19:38.535211Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = list(map(lambda x: [x, *vectors[x]], vectors.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:19:39.865875Z",
     "start_time": "2018-01-12T10:19:39.776063Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(c, columns=['text', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:19:40.303551Z",
     "start_time": "2018-01-12T10:19:40.288371Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(g):\n",
    "    return sum([g[i] for i in g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:19:45.250371Z",
     "start_time": "2018-01-12T10:19:40.844591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-7e184cb91260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         data_proto['size_%s' % month] = [new_cool[p][year][month]\n\u001b[0;32m----> 6\u001b[0;31m                                          for p in data_proto['text']]\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#data_proto['size_%s' % month] = data_proto['size_%s' % month]/data_proto['size_%s' % month].max()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-7e184cb91260>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         data_proto['size_%s' % month] = [new_cool[p][year][month]\n\u001b[0;32m----> 6\u001b[0;31m                                          for p in data_proto['text']]\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#data_proto['size_%s' % month] = data_proto['size_%s' % month]/data_proto['size_%s' % month].max()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for year in tqdm(list(reversed(list(years)))):\n",
    "    data_proto = data.copy()\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        data_proto['size_%s' % month] = [new_cool[p][year][month]\n",
    "                                         for p in data_proto['text']]\n",
    "        #data_proto['size_%s' % month] = data_proto['size_%s' % month]/data_proto['size_%s' % month].max()\n",
    "        data_proto = data_proto.fillna(0)\n",
    "\n",
    "    def f(g):\n",
    "        return sum([g[i] for i in g])\n",
    "\n",
    "    data_proto['size_year'] = [f(new_cool[p][year])\n",
    "                               for p in data_proto['text']]\n",
    "    data_proto = data_proto.sort_values(['size_year'], ascending=False)[\n",
    "        :20000].to_csv('output2/data_{}.csv'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:20:14.612971Z",
     "start_time": "2018-01-12T10:20:14.097749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘output_csv_uskills’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir output_csv_uskills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:20:37.035224Z",
     "start_time": "2018-01-12T10:20:18.560705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm(years):\n",
    "    data_proto = data.copy()\n",
    "\n",
    "    data_proto['size'] = [f(new_cool[p][year]) for p in data_proto['text']]\n",
    "    data_proto['size'] = data_proto['size'] / data_proto['size'].max()\n",
    "    data_proto.sort_values(['size'], ascending=False)[:20000].to_csv(\n",
    "        'output_csv_uskills/data_%s.csv' % year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-29T10:30:28.648976Z",
     "start_time": "2017-12-29T10:30:25.100786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm output_csv_uskills.zip\n",
    "!zip -r output_csv_uskills.zip output_csv_uskills/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:34:47.924238Z",
     "start_time": "2018-01-12T10:34:47.611979Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skill_id_to_uskill_id = {}\n",
    "\n",
    "for key in id_to_simmilar:\n",
    "    skill_id_to_uskill_id[key] = key\n",
    "    \n",
    "    for skill_key in id_to_simmilar[key]:\n",
    "        skill_id_to_uskill_id[skill_key[0]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:35:18.118220Z",
     "start_time": "2018-01-12T10:35:18.090832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496951"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(skill_id_to_uskill_id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:34:50.849104Z",
     "start_time": "2018-01-12T10:34:50.832385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166164"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_id_to_uskill_id[clear_skill_to_id[vac_to_skills[10000][0]['real_skill']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:37:19.992224Z",
     "start_time": "2018-01-12T10:37:19.972898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TLD(v: Vacancy):\n",
    "    tmp = []\n",
    "    for i in vac_to_skills[v.id]:\n",
    "        if i['real_skill'] in clear_skill_to_id:\n",
    "            my_id = clear_skill_to_id[i['real_skill']]\n",
    "            if my_id in skill_id_to_uskill_id:\n",
    "                answer = skill_id_to_uskill_id[my_id]\n",
    "                if answer not in tmp:\n",
    "                    tmp.append(skill_to_skill[skill_id_to_skill[answer]])\n",
    "    return gensim.models.doc2vec.TaggedDocument(tmp, (v.id,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:37:33.757434Z",
     "start_time": "2018-01-12T10:37:21.066160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tlds = tuple(map(TLD, all_vacancies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:37:41.368128Z",
     "start_time": "2018-01-12T10:37:41.332795Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tlds = list(filter(None, tlds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:37:42.038022Z",
     "start_time": "2018-01-12T10:37:42.022068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841447"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tlds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:43:14.904259Z",
     "start_time": "2018-01-12T10:37:46.952689Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(\n",
    "    tlds,\n",
    "    size=50, window=2, min_count=1, sample=1e-5, iter=10, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:48:13.762117Z",
     "start_time": "2018-01-12T10:47:57.341726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 841447/841447 [00:16<00:00, 51306.43it/s]\n"
     ]
    }
   ],
   "source": [
    "skill_to_usd = {}\n",
    "for vac in tqdm(all_vacancies):\n",
    "    for skill in vac_to_skills[vac.id]:\n",
    "        skill_name = skill['real_skill']\n",
    "        if vac.salary != 0:\n",
    "            if skill_name in skill_to_usd:\n",
    "                skill_to_usd[skill_name].append(vac.salary)\n",
    "            else:\n",
    "                skill_to_usd[skill_name] = [vac.salary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:48:15.243469Z",
     "start_time": "2018-01-12T10:48:15.228475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(arr):\n",
    "    return np.asarray(arr).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:48:36.162543Z",
     "start_time": "2018-01-12T10:48:15.965903Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2358899/2358899 [00:20<00:00, 116894.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(skill_to_usd):\n",
    "    skill_to_usd[key] = mean(skill_to_usd[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T10:48:41.283850Z",
     "start_time": "2018-01-12T10:48:41.259817Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kk = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-12T10:48:41.896Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://88.99.252.225:8081/ (Press CTRL+C to quit)\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:44] \"GET /demo HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:46] \"GET /get_all?term=c HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:52] \"GET /get_word?words=%5B%22c%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%BD%D0%BE%D0%B5+%D0%BC%D1%8B%D1%88%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5%22%2C%22%22%5D HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:59] \"GET /demo2 HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:59] \"GET /static/css/scatter.css HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:59] \"GET /static/js/scatter.js HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:59] \"GET /static/js/d3-tip.js HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:48:59] \"GET /static/images/tick.png HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:49:00] \"GET /output_csv/data_2003.csv HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:50:19] \"GET /output_csv/data_2004.csv HTTP/1.1\" 200 -\n",
      "94.127.216.116 - - [12/Jan/2018 11:53:25] \"GET /output_csv/data_2005.csv HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, send_from_directory\n",
    "import os\n",
    "os.putenv('LANG', 'ru_RU.UTF-8')\n",
    "os.putenv('LC_ALL', 'ru_RU.UTF-8')\n",
    "from datetime import timedelta\n",
    "from flask import make_response, request, current_app\n",
    "from functools import update_wrapper\n",
    "\n",
    "\n",
    "def crossdomain(origin=None, methods=None, headers=None,\n",
    "                max_age=21600, attach_to_all=True,\n",
    "                automatic_options=True):\n",
    "    if methods is not None:\n",
    "        methods = ', '.join(sorted(x.upper() for x in methods))\n",
    "    if headers is not None:\n",
    "        headers = ', '.join(x.upper() for x in headers)\n",
    "    if isinstance(max_age, timedelta):\n",
    "        max_age = max_age.total_seconds()\n",
    "\n",
    "    def get_methods():\n",
    "        if methods is not None:\n",
    "            return methods\n",
    "\n",
    "        options_resp = current_app.make_default_options_response()\n",
    "        return options_resp.headers['allow']\n",
    "\n",
    "    def decorator(f):\n",
    "        def wrapped_function(*args, **kwargs):\n",
    "            if automatic_options and request.method == 'OPTIONS':\n",
    "                resp = current_app.make_default_options_response()\n",
    "            else:\n",
    "                resp = make_response(f(*args, **kwargs))\n",
    "            if not attach_to_all and request.method != 'OPTIONS':\n",
    "                return resp\n",
    "\n",
    "            h = resp.headers\n",
    "\n",
    "            h['Access-Control-Allow-Origin'] = origin\n",
    "            h['Access-Control-Allow-Methods'] = get_methods()\n",
    "            h['Access-Control-Max-Age'] = str(max_age)\n",
    "            if headers is not None:\n",
    "                h['Access-Control-Allow-Headers'] = headers\n",
    "            return resp\n",
    "\n",
    "        f.provide_automatic_options = False\n",
    "        return update_wrapper(wrapped_function, f)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/get_all\")\n",
    "@crossdomain(origin='*')\n",
    "def k():\n",
    "    now = request.args['term']\n",
    "\n",
    "    tmp = []\n",
    "    for i in kk:\n",
    "        if now in i:\n",
    "            tmp.append(i)\n",
    "\n",
    "            if len(tmp) == 10:\n",
    "                break\n",
    "\n",
    "    return json.dumps(tmp)\n",
    "\n",
    "\n",
    "@app.route(\"/demo\")\n",
    "@crossdomain(origin='*')\n",
    "def j():\n",
    "    return render_template('demo.html')\n",
    "\n",
    "\n",
    "@app.route(\"/demo2\")\n",
    "@crossdomain(origin='*')\n",
    "def jj():\n",
    "    return render_template('demo2.html')\n",
    "\n",
    "\n",
    "@app.route('/output_csv/<path:path>')\n",
    "def send_js(path):\n",
    "    return send_from_directory('static/js/output_csv', path)\n",
    "\n",
    "\n",
    "@app.route(\"/get_word\")\n",
    "@crossdomain(origin='*')\n",
    "def hello():\n",
    "    ans = list(filter(lambda x: len(x) > 0, eval(request.args['words'])))\n",
    "    ans = model.most_similar_cosmul(positive=ans)\n",
    "    ans = sorted([[mean(skill_to_usd[i[0]]), i[0]] for i in ans])\n",
    "    ans = list(reversed(ans))\n",
    "    return json.dumps({'skills': ans})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"88.99.252.225\", port=8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
